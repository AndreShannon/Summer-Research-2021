{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DiffBins.ipynb","provenance":[{"file_id":"1qEZ3IKSdogPpw3QApZmt1lC0X7MwZJ8C","timestamp":1625601080758},{"file_id":"1nBdEnIHwviYEWLyIJaBDLvHChyVXWFC1","timestamp":1625063823187}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wNUfL4QlsBG","executionInfo":{"status":"ok","timestamp":1644882301417,"user_tz":300,"elapsed":10859,"user":{"displayName":"Andre Shannon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13527615394422287040"}},"outputId":"9f8cd0ad-0188-4a38-cab9-4f0073b6de3a"},"source":["!pip install automatic_speech_recognition\n","# !pip install numpy\n","# !pip install pandas\n","# !pip install scipy\n","# !pip install sklearn"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting automatic_speech_recognition\n","  Downloading automatic_speech_recognition-1.0.4-py3-none-any.whl (40 kB)\n","\u001b[?25l\r\u001b[K     |████████▏                       | 10 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 20 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 2.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from automatic_speech_recognition) (1.4.1)\n","Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from automatic_speech_recognition) (1.18.1)\n","Collecting python-speech-features\n","  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from automatic_speech_recognition) (1.3.5)\n","Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.7/dist-packages (from automatic_speech_recognition) (2.7.0)\n","Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from automatic_speech_recognition) (3.7.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.6.3)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (0.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (2.7.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (3.3.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.19.5)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (13.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.15.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (3.17.3)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (2.7.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.43.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.1.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (3.1.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (0.24.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (0.37.1)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (2.7.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (3.10.0.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->automatic_speech_recognition) (1.13.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.0->automatic_speech_recognition) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (2.23.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.0->automatic_speech_recognition) (3.2.0)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->automatic_speech_recognition) (1.0.3)\n","Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->automatic_speech_recognition) (0.4.1)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->automatic_speech_recognition) (1.26.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->automatic_speech_recognition) (1.54.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->automatic_speech_recognition) (2018.9)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->automatic_speech_recognition) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->automatic_speech_recognition) (3.0.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->automatic_speech_recognition) (2.8.2)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables->automatic_speech_recognition) (2.8.1)\n","Building wheels for collected packages: python-speech-features\n","  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=216c5035f5ba15c6078af9654647758f6fb7271e3043d3916553b44524213290\n","  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n","Successfully built python-speech-features\n","Installing collected packages: python-speech-features, automatic-speech-recognition\n","Successfully installed automatic-speech-recognition-1.0.4 python-speech-features-0.6\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRhmExY9lw0Y","executionInfo":{"status":"ok","timestamp":1644882349629,"user_tz":300,"elapsed":48287,"user":{"displayName":"Andre Shannon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13527615394422287040"}},"outputId":"ad8a203e-146a-4cdf-c0cc-e9f5d5a45a84"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"MFi83aaNjMdx"},"source":["# Define the binning methods\n","\n","# ------- Logorithmic Spacing Bins (Mel Scale) ----------\n","def getMelBins(numBins, highFreq):\n","    # formula for hertz to mel\n","    # m = 1127 * natural log(1 + f/700)\n","    # formula for mel to hertz\n","    # f = 700*(e^(m/1127) - 1)\n","\n","    # Map biggest freq to mel scale\n","    # Do evenly spaced sampling along the mel scale\n","    # Map those back to hertz to get our mel-like log scale\n","\n","    # Upper bound for mel\n","    stop = 1127 * np.log(1 + highFreq/700)\n","    # print(\"Upper Mel: \", stop)\n","\n","    mels = np.linspace(0, stop, num=numBins + 1)\n","    # print(\"Mels: \", mels)\n","    \n","    # inverse of mel to hertz\n","    binEdges1 = 700*(np.exp(mels/1127) - 1)\n","\n","    # Cast to integers\n","    binEdges1 = binEdges1.astype(int)\n","\n","    # Convert to array of two tuples (each bin with its start and end)\n","    binEdges = []\n","    for i in range(len(binEdges1)-1):\n","        binEdges.append((binEdges1[i], binEdges1[i+1]))\n","\n","    return binEdges\n","\n","# call:\n","# binEdges = getMelBins(NUM_BINS, len(halfDFT) - 1)\n","# -------- Logorithmic Spacing Bins ----------\n","\n","\n","# -------- Evenly Spaced Bins --------\n","def getEvenBins(numBins, highFreq):\n","    binEdges1 = np.linspace(0, highFreq, num=numBins + 1).astype(int)\n","\n","    # Convert to array of two tuples (each bin with its start and end)\n","    binEdges = []\n","    for i in range(len(binEdges1)-1):\n","        binEdges.append([binEdges1[i], binEdges1[i+1]])\n","\n","    return binEdges\n","\n","# call:\n","# binEdges = getEvenBins(NUM_BINS, len(halfDFT) - 1)\n","# -------- Evenly Spaced Bins --------\n","\n","\n","# -------- Overlapping Evenly Spaced Bins --------\n","def getOverlappingEvenBins(numBins, highFreq):\n","    nFirstBins = np.ceil(numBins/2).astype(int)\n","    # nSecondBins = nFirstBins - 1\n","\n","    binEdges1 = getEvenBins(nFirstBins, highFreq)\n","\n","    # create bins halfway between other bins\n","    binEdges2 = []\n","    for i in range(len(binEdges1) - 1):\n","        binEdges2.append([((binEdges1[i][0] + binEdges1[i][1])/2).astype(int), ((binEdges1[i+1][0] + binEdges1[i+1][1])/2).astype(int)])\n","    \n","    # combine into an array of two tuples (each bin with its start and end)\n","    binEdges = []\n","    for i in range(len(binEdges1)):\n","        binEdges.append(binEdges1[i])\n","        if i < len(binEdges2):\n","            binEdges.append(binEdges2[i])\n","\n","    return binEdges\n","\n","# call:\n","# binEdges = getOverlappingEvenBins(NUM_BINS, len(halfDFT) - 1)\n","# -------- Overlapping Evenly Spaced Bins --------\n","\n","\n","# -------- Bins Based on Peaks --------\n","def getPeakBins(halfDFT, DOWN_SAMPLE_FACTOR):\n","    filteredDft = np.convolve(np.abs(halfDFT), np.array([0.5] * 5))\n","    # DOWN_SAMPLE_FACTOR = 8\n","    DOWN_SAMPLE_FACTOR = DOWN_SAMPLE_FACTOR\n","    idxs = np.arange(0, len(filteredDft), step=DOWN_SAMPLE_FACTOR)\n","    dsDft = filteredDft[idxs]\n","\n","    peaks, peakProps = sc.signal.find_peaks(\n","    dsDft,\n","    # threshold=0.01 * (np.max(dsDft) - np.min(dsDft)),\n","    prominence=0.01 * (np.max(dsDft) - np.min(dsDft)),\n","    width=(0, 5),\n","    wlen=3 # maybe change to 5\n","    )\n","\n","    _peakWindows = []\n","    lenp = len(peaks)\n","    for i, p in enumerate(peaks):\n","        if i == 0:\n","            _peakWindows.append((0, int(p / 2)))\n","            p0 = int(p / 2)\n","        else:\n","            p0 = _peakWindows[-1][1]\n","\n","        p1 = peaks[i + 1] if i < lenp - 1 else len(dsDft) - 1\n","        p1 = int((p1 - p) / 2 + p)\n","\n","        _peakWindows.append((p0, p1))\n","\n","        if i == lenp - 1:\n","            _peakWindows.append((_peakWindows[-1][1], len(dsDft) - 1))\n","\n","    # ensure they index into original DFT\n","    _peakWindows = [\n","        (left * DOWN_SAMPLE_FACTOR, right * DOWN_SAMPLE_FACTOR) for left, right in _peakWindows\n","    ]\n","\n","    if _peakWindows[-1][1] != len(halfDFT) - 1:\n","        _peakWindows[-1] = (_peakWindows[-1][0], len(halfDFT) - 1)\n","\n","    peakWindows = np.array(_peakWindows)\n","\n","    return peakWindows\n","    \n","# call:\n","# binEdges = getPeakBins(halfDFT, 8)\n","\n","# # x_p = np.ones((1, len(_peakWindows)))\n","# -------- Bins Based on Peaks --------\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"haBT00MW82Vc"},"source":["import numpy as np\n","\n","# Based on LEMNA, using Gaussian Mixture Models to model decision boundary\n","# Returning all the models & clusters and the index of the model that contains \n","# the original point (original point should be idx 0 of points and labels)\n","\n","# This is NOT finished!!!\n","# It runs, but I am not sure it is doing what it is supposed to...\n","\n","def predictWithGMM(points, labels, gmm, n_compontents):\n","    # gmm = BayesianGaussianMixture(n_components=n_components, covariance_type='full')\n","    data = np.concatenate((points, labels.reshape((1, -1)).T), axis=1)\n","    # for i in data:\n","    #     data[i].append(labels[i])\n","\n","    # should the clusters be based on the points and labels or just points?\n","    gmm.fit(data) \n","\n","    models = [Ridge() for _ in range(n_components)]\n","    clusters = [[] for _ in range(n_components)]\n","\n","    for i in range(n_components):\n","        clusters[i] = np.argwhere(gmm.predict(data) == i).T[0]\n","        # clusters[i] = np.argwhere(gmm.predict(X.T) == i).T[0]\n","\n","    # for i in range(n_components):\n","    #     print(\"Cluster \", i, \" dimensions: \", clusters[i].shape)\n","    #     # print(clusters[i])\n","    # print(\"Points dimensions: \", points.shape)\n","\n","    for i, m in enumerate(models):\n","        if len(clusters[i]) != 0:\n","            m.fit(points[clusters[i]], labels[clusters[i]])\n","            # m.fit(X[0][clusters[i].reshape(-1,1)], X[1][clusters[i]])\n","    \n","    bestModel = 0\n","\n","    for i in range(len(clusters)):\n","        if data[0] in clusters[i]:\n","            bestModel = i\n","            break\n","\n","    return models, clusters, bestModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For testing\n","# Testing retriving data stored\n","\n","# import pandas as pd\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from sklearn.mixture import BayesianGaussianMixture\n","# from sklearn.linear_model import Ridge\n","\n","# !pwd\n","# %cd /content/drive/MyDrive/Summer Research 2021/\n","# d = pd.read_csv('c_2k_Testing3.csv')\n","\n","\n","# z_pTest = []\n","# for i in range(len(d['z_p'])):\n","#     z_pTest.append(eval(d['z_p'][i]))\n","\n","# z_pTest = np.array(z_pTest)\n","# print(z_pTest.shape)\n","\n","# z_labsTest = []\n","# for i in range(len(d['z_labs'])):\n","#     z_labsTest.append(eval(d['z_labs'][i]))\n","\n","# z_labsTest = np.array(z_labsTest)\n","# print(z_labsTest.shape)\n","\n","# # for i in range(5):\n","# #     print(z_pTest[i][0][0])\n","# #     print(z_labsTest[i][0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3G4R7NnWYbk","executionInfo":{"status":"ok","timestamp":1644882351716,"user_tz":300,"elapsed":1936,"user":{"displayName":"Andre Shannon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13527615394422287040"}},"outputId":"9fd7ce1c-58fa-4939-b6e8-6cdb110390ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/MyDrive/Summer Research 2021\n","(5, 1, 2001, 25)\n","(5, 1, 2001)\n"]}]},{"cell_type":"code","source":["# Testing continued\n","# Testing Gaussian Mixture Model\n","# Also trying to see if I could use tqdm to get a runtime status\n","\n","# import tqdm\n","\n","# # GMM model\n","# n_components = 10\n","\n","# for i in tqdm.trange(5, desc=f\"Clustering Using Gaussian Mixture Model\"):\n","#     gmm = BayesianGaussianMixture(n_components=n_components, covariance_type='full')\n","#     models, clusters, bestIdx = predictWithGMM(z_pTest[i][0], z_labsTest[i][0], gmm, n_components)\n","#     # print(models[bestIdx].coef_)\n","\n","\n","# # perturbations = tqdm.trange(self.nPert, desc=f\"Perturbing Image\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"md5MqUlI9PoX","executionInfo":{"status":"ok","timestamp":1644882359356,"user_tz":300,"elapsed":7651,"user":{"displayName":"Andre Shannon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13527615394422287040"}},"outputId":"a9724f47-86e7-4c64-8901-1a4bd75c50e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Clustering Using Gaussian Mixture Model:   0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","Clustering Using Gaussian Mixture Model:  20%|██        | 1/5 [00:01<00:06,  1.51s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","Clustering Using Gaussian Mixture Model:  40%|████      | 2/5 [00:02<00:03,  1.31s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","Clustering Using Gaussian Mixture Model:  60%|██████    | 3/5 [00:04<00:02,  1.31s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","Clustering Using Gaussian Mixture Model:  80%|████████  | 4/5 [00:06<00:01,  1.61s/it]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","Clustering Using Gaussian Mixture Model: 100%|██████████| 5/5 [00:07<00:00,  1.52s/it]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6juYoQqmfiR","executionInfo":{"status":"ok","timestamp":1644882366416,"user_tz":300,"elapsed":7073,"user":{"displayName":"Andre Shannon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13527615394422287040"}},"outputId":"63d6da07-0fde-4e70-ed55-f4e5dd439aff"},"source":["!pwd\n","%cd /content/drive/MyDrive/Summer Research 2021/\n","\n","import pandas as pd\n","import pickle\n","# import explainableai\n","import matplotlib.pyplot as plt\n","import random\n","import numpy as np\n","import scipy as sc\n","import scipy.signal\n","import automatic_speech_recognition as asr\n","from sklearn.linear_model import Ridge\n","from sklearn import metrics\n","import random\n","from pathlib import Path\n","from enum import Enum\n","from sklearn.mixture import BayesianGaussianMixture\n","import sys\n","\n","\n","\n","class BinMethod(Enum):\n","    EVEN = 1\n","    OVERLAPPING = 2\n","    MEL = 3\n","    PEAK = 4\n","\n","# class InterpModel(Enum):\n","\n","\n","\n","N = 5         # Limiting the number of different audio samples we use\n","abc = 'c'     # hmm, I think we also define char = 'c' and use that later\n","# dictionary to story all the data \n","dict = {\n","    #  'char' : [c for c in abc],\n","     'correct after perturbations %': [[] for _ in range(N)],\n","    #  'correct perturbations avg': [0 for _ in range(len(abc))],\n","     'audio name': ['' for _ in range(N)],\n","     'normalized': [[] for _ in range(N)],\n","     'origConf': [[] for _ in range(N)],\n","     'avgPertConf': [[] for _ in range(N)],\n","     'binMethod': [[] for _ in range(N)],\n","     'numBins': [[] for _ in range(N)],\n","     'binEdges': [[] for _ in range(N)],\n","     'overlapping': [[] for _ in range(N)],\n","     'sigma': [[] for _ in range(N)],\n","     'mse': [[] for _ in range(N)],\n","     'mse avg': [0 for _ in range(N)],\n","     'r2': [[] for _ in range(N)],\n","     'r2 avg': [0 for _ in range(N)],\n","     'z_p': [[] for _ in range(N)],\n","     'z_labs': [[] for _ in range(N)],\n","     'weights': [[] for _ in range(N)],\n","     'coefs': [[] for _ in range(N)]\n","    }\n","dict"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Summer Research 2021\n","/content/drive/MyDrive/Summer Research 2021\n"]},{"output_type":"execute_result","data":{"text/plain":["{'audio name': ['', '', '', '', ''],\n"," 'avgPertConf': [[], [], [], [], []],\n"," 'binEdges': [[], [], [], [], []],\n"," 'binMethod': [[], [], [], [], []],\n"," 'coefs': [[], [], [], [], []],\n"," 'correct after perturbations %': [[], [], [], [], []],\n"," 'mse': [[], [], [], [], []],\n"," 'mse avg': [0, 0, 0, 0, 0],\n"," 'normalized': [[], [], [], [], []],\n"," 'numBins': [[], [], [], [], []],\n"," 'origConf': [[], [], [], [], []],\n"," 'overlapping': [[], [], [], [], []],\n"," 'r2': [[], [], [], [], []],\n"," 'r2 avg': [0, 0, 0, 0, 0],\n"," 'sigma': [[], [], [], [], []],\n"," 'weights': [[], [], [], [], []],\n"," 'z_labs': [[], [], [], [], []],\n"," 'z_p': [[], [], [], [], []]}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"YJJazxD3kxmK","executionInfo":{"status":"error","timestamp":1644882460842,"user_tz":300,"elapsed":94442,"user":{"displayName":"Andre Shannon","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13527615394422287040"}},"outputId":"e262af7a-c4e9-4062-dade-9f14b36c5b58"},"source":["# %%\n","# loading pipeline outside of the for loops so it is not loaded 50 times\n","pipeline = asr.load('deepspeech2', lang='en')\n","\n","# maxAmps = [5000, 10000, 15000, 20000, 25000]\n","# numBins = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n","# numBins = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n","# numBins = [25, 40, 50, 100]\n","# sigmas = [0, .25, .5, .75, 1, np.sqrt(2), 1.5, 2, 2.5, 3, 5]\n","\n","# for sig in sigmas:\n","for _ in range(1):\n","# for amp in maxAmps:\n","# for nBins in numBins:\n","    char = 'c'\n","    ALPHABET = ' abcdefghijklmnopqrstuvwxyz\\'-'\n","    originalPercentage_ = []\n","    mse_ = []\n","    r2_ = []\n","    coefs_ = []\n","    audio_index = 0\n","\n","    alignDir = Path('audio/alignments').expanduser().absolute()\n","    csvPaths = list(alignDir.rglob('*.csv'))\n","    df = pd.DataFrame()\n","    for csv in csvPaths:\n","        df = pd.concat((df, pd.read_csv(csv.as_posix())))\n","    metaData = df\n","    metaData['file_loc'] = metaData['file_loc'].apply(lambda x: Path(x).relative_to('speech_commands').as_posix())\n","\n","    charTable = metaData.loc[metaData['letter'] == char]\n","    charTable = charTable[:N]  # Only using first N samples\n","    print(charTable)\n","    k = 0\n","\n","    MAX_AMP = 20000\n","    print(\"Normalizing between\", -MAX_AMP, \"and\", MAX_AMP)\n","    NUM_BINS = 25\n","    # BIN_METH could be EVEN, MEL, or PEAK\n","    # BIN_METH can be EVEN or OVERLAPPING\n","    BIN_METH = BinMethod.EVEN\n","    if (BIN_METH == BinMethod.OVERLAPPING):\n","        OVERLAPPING = True\n","    else:\n","        OVERLAPPING = False\n","\n","    print(\"Using\", NUM_BINS, end='')\n","\n","    # if (BIN_METH == BinMethod.EVEN):\n","    #     print(\" evenly spaced bins\")\n","    # elif (BIN_METH == BinMethod.OVERLAPPING):\n","    #     print(\" overlapping evenly spaced\")\n","\n","    if (BIN_METH == BinMethod.EVEN):\n","        print(\" evenly spaced\", end='')\n","    elif (BIN_METH == BinMethod.MEL):\n","        print(\" mel spaced\", end='')\n","    elif (BIN_METH == BinMethod.PEAK):\n","        print(\" peak spaced\", end='')\n","\n","    if (OVERLAPPING):\n","        print(\" overlapping bins\")\n","    else:\n","        print(\" bins\")\n"," \n","\n","\n","    for _, row in charTable.iterrows():\n","        print('k is', k)\n","        charMeta = {'character': char, 'alphabetIdx': ALPHABET.index(char), 'alignIdx': row['alignment_index'], 'startIdx': row['st'], 'endIdx': row['ed'] }\n","        fileName = f'audio/speech_commands/{row[\"file_loc\"]}'\n","        dict['audio name'][audio_index] = fileName\n","        audio_index += 1\n","        # print(charMeta)\n","\n","        instance = asr.utils.read_audio(fileName)\n","        instance = np.pad(instance, 3000, 'reflect')\n","\n","        # ----------------Normalize------------------\n","        # Want to normalize data between -MAX_AMP and MAX_AMP\n","        dict['normalized'][k].append(MAX_AMP)\n","\n","        # print(\"dict['normalized']: \", dict['normalized'])\n","\n","        # print(\"Instance: \", instance)\n","        maxAmp = instance[np.argmax(instance)]\n","        minAmp = instance[np.argmin(instance)]\n","        # print(\"maximum Amplitude: \", maxAmp)\n","        # print(\"minimum Amplitude: \", minAmp)\n","        \n","        maxMin = np.array([maxAmp, np.abs(minAmp)])\n","        maxMag = maxMin[np.argmax(maxMin)]\n","        # print(\"Maximum magnitude: \", maxMag)\n","\n","        # plt.figure(figsize=(15, 9))\n","        # plt.subplot(1,1,1)\n","        # plt.title('Padded Audio')\n","        # plt.plot(instance)\n","\n","        instance = instance/maxMag * MAX_AMP\n","        # print(\"Normalized instance: \", normInstance)\n","        # print(\"Normalized max: \", normInstance[np.argmax(normInstance)])\n","        # print(\"Normalized min: \", normInstance[np.argmin(normInstance)])\n","        # ----------------End Normalize------------------\n","\n","\n","        dft = sc.fft.fft(instance[charMeta['startIdx']:charMeta['endIdx']])\n","        halfDFT = dft[:int(np.floor(dft.shape[0] / 2.0) + 1)]\n","\n","\n","\n","        # # Get bins\n","        # # for fixed bins, all bins start at 1 (not bothering with a threshold)\n","        # if (OVERLAPPING):\n","        #     nFirstBins = np.ceil(NUM_BINS/2).astype(int)\n","        #     # nSecondBins = nFirstBins - 1\n","\n","        #     if (BIN_METH == BinMethod.EVEN):\n","        #         binEdges1 = getEvenBins(nFirstBins, len(halfDFT) - 1)\n","        #     elif (BIN_METH == BinMethod.MEL):\n","        #         binEdges1 = getMelBins(nFirstBins, len(halfDFT) - 1)\n","        #     elif (BIN_METH == BinMethod.PEAK):\n","        #         binEdges1 = getPeakBins(halfDFT, 8)\n","\n","        #     # create bins halfway between other bins\n","        #     binEdges2 = []\n","        #     for i in range(len(binEdges1) - 1):\n","        #         binEdges2.append((((binEdges1[i][0] + binEdges1[i][1])/2).astype(int), ((binEdges1[i+1][0] + binEdges1[i+1][1])/2).astype(int)))\n","            \n","        #     # combine into an array of two tuples (each bin with its start and end)\n","        #     binEdges = []\n","        #     for i in range(len(binEdges1)):\n","        #         binEdges.append(binEdges1[i])\n","        #         if i < len(binEdges2):\n","        #             binEdges.append(binEdges2[i])\n","\n","        # else:\n","        #     if (BIN_METH == BinMethod.EVEN):\n","        #         binEdges = getEvenBins(NUM_BINS, len(halfDFT) - 1)\n","        #     elif (BIN_METH == BinMethod.MEL):\n","        #         binEdges = getMelBins(NUM_BINS, len(halfDFT) - 1)\n","        #     elif (BIN_METH == BinMethod.PEAK):\n","        #         binEdges = getPeakBins(halfDFT, 8)\n","\n","        if (BIN_METH == BinMethod.EVEN):\n","            binEdges = getEvenBins(NUM_BINS, len(halfDFT) - 1)\n","        elif (BIN_METH == BinMethod.OVERLAPPING):\n","            binEdges = getOverlappingEvenBins(NUM_BINS, len(halfDFT) - 1)\n","\n","\n","        # print()\n","        # print(\"Length of halfDFT: \", len(halfDFT))\n","        # # print(\"step: \", step)\n","        # print(\"Length of binEdges: \", len(binEdges))\n","        # print(\"binEdges: \", binEdges)\n","        # print()\n","\n","\n","        x_p = np.ones((1, len(binEdges)))\n","\n","\n","        # Define num perturbations and % max allowable perturbations\n","        numPerturb = 2000\n","        pMaxAllowablePerturb = 0.25\n","\n","        # Max bins to perturn\n","        nMaxToPerturb = int(np.floor(pMaxAllowablePerturb * x_p.shape[1]))\n","        # Range of perturbations\n","        nToPerturbRange = list(np.arange(1, nMaxToPerturb + 1))\n","        # Create array of ones\n","        p = np.ones((numPerturb, x_p.shape[1]))\n","      \n","        for i in range(numPerturb):\n","            # perturbing all bins\n","            samplePop = list(np.arange(0, int(x_p.shape[1])))\n","            numIdxs = int(random.sample(nToPerturbRange, 1)[-1])\n","            idxs = random.sample(samplePop, numIdxs)\n","            idxs = np.array(idxs).astype(int)\n","            p[i, idxs] = 0\n","\n","        z_p = np.concatenate((x_p.real, p), axis=0)\n","        interpInstance = z_p\n","        # Number of perturbed samples\n","        nPerturbed = interpInstance.shape[0]\n","\n","\n","        perturbedDFT = np.repeat([halfDFT], nPerturbed, axis=0)\n","        # Interpolate where bin is equal to 0\n","        for p in range(nPerturbed):\n","            for i in np.argwhere(interpInstance[p, :] == 0).flatten().tolist():\n","                # only remove the zeroed out peaks\n","                # left, right = peakWindows[i, :]\n","                left, right = binEdges[i]\n","                # left = binEdges[i]\n","                # right = binEdges[i+1]\n","                # perturbedDFT[p, left: right + 1] = np.interp(\n","                #     range(left, right + 1),\n","                #     [left, right],\n","                #     [perturbedDFT[p, left], perturbedDFT[p, right]]\n","                # )\n","\n","                # perturb using noise\n","                # perturbedDFT[p, left: right + 1] = (np.random.uniform(-4, 4, (right+1-left,)) + 1j*np.random.uniform(-4, 4,(right+1-left,)))\n","                # perturb by setting intensity of frequencies to 0\n","                perturbedDFT[p, left: right + 1] = np.zeros(right+1-left)\n","                \n","                # if(p == 1):\n","                #   print(\"Perturbing frequencies \", left, \" to \", right)\n","        \n","        # print()\n","        # print(\"interpInstance[1]: \", interpInstance[1])\n","        # print(\"perturbedDFT[1]: \", perturbedDFT[1])\n","\n","        # plt.figure(figsize=(15, 9))\n","        # plt.subplot(1,1,1)\n","        # plt.title('Perturbed audio sample using 0s')\n","        # plt.plot(perturbedDFT[1])\n","\n","\n","\n","        flipped = np.conj(np.flip(perturbedDFT, axis=1))\n","        flipped = flipped[:, 1:-1] if dft.shape[0] % 2 == 0 else flipped[:, :-1]\n","        perturbedDFT = np.concatenate((perturbedDFT, flipped), axis=1)\n","\n","        batchAudio = np.zeros_like(perturbedDFT.real)\n","\n","        for i in range(nPerturbed):\n","            batchAudio[i, :] = (sc.fft.ifft(perturbedDFT[i, :])).real\n","\n","        output = np.repeat([instance], interpInstance.shape[0], axis=0)\n","        output[:, charMeta['startIdx']:charMeta['endIdx']] = batchAudio\n","        z = output\n","\n","        # Extract spectrogram features\n","        features = pipeline._features_extractor(z)\n","        # Forward propagate \n","        # TODO possibly use tqdm to give progress bar while running\n","        batchLogits = pipeline._model.predict(features)\n","        # Use softmax on the last layer\n","        charLogits = sc.special.softmax(batchLogits[:, charMeta['alignIdx'], :], axis=1)\n","\n","        # Look at the probability at index 3 for c\n","        z_labs = charLogits[:, charMeta['alphabetIdx']]\n","        count = 0\n","        for c in charLogits:\n","            count += 1 if np.argmax(c) == charMeta['alphabetIdx'] else 0\n","\n","        # magic happens here\n","        # originalPercentage_.append(count/charLogits.shape[0])\n","\n","\n","        def _normalize(x, _min, _max):\n","            x = x.astype(np.int32)\n","            output = (x - _min) / (_max - _min)\n","            return output\n","\n","        def distanceL2(x, z, charMeta):\n","            dMin, dMax = np.iinfo(np.int16).min, np.iinfo(np.int16).max\n","            xnorm = _normalize(x[charMeta['startIdx']:charMeta['endIdx']], dMin, dMax)\n","            znorm = _normalize(z[charMeta['startIdx']:charMeta['endIdx']], dMin, dMax)\n","\n","            return np.linalg.norm(xnorm - znorm)\n","\n","\n","\n","        d_p = np.apply_along_axis(lambda a: distanceL2(instance, a, charMeta), axis=1, arr=z)\n","        d = d_p\n","        sigma = np.sqrt(np.std(d))\n","        # if (sig == 0):\n","        #     sigma = np.sqrt(np.std(d))\n","        # else:\n","        #     sigma = sig\n","        weights = np.exp(-(d**2)/ sigma ** 2.0)\n","\n","        # print()\n","        # # print(\"distances: \", d)\n","        # # print(\"sigma: \", sigma)\n","        # # print(\"weights: \", weights)\n","        # print(\"sigma: \", sigma)\n","        # print(\"sqrt of std of distances:\", np.sqrt(np.std(d)))\n","        # print(\"max distance:\", d[np.argmax(d)])\n","        # print(\"min weight:\", weights[np.argmin(weights)])\n","        # print(\"average distance:\", np.average(d))\n","        # print(\"average weight:\", np.average(weights))\n","        # print()\n","\n","        # GMM model (LEMNA)\n","        n_components = 10\n","        gmm = BayesianGaussianMixture(n_components=n_components, covariance_type='full')\n","        # model = predictWithGMM(z_p, z_labs, gmm, n_components)\n","        models, clusters, bestIdx = predictWithGMM(z_p, z_labs, gmm, n_components)\n","        model = models[bestIdx]\n","        y_pred = model.predict(z_p)\n","        r2 = model.score(z_p[clusters[bestIdx]], z_labs[clusters[bestIdx]])\n","        mse = metrics.mean_squared_error(z_labs[clusters[bestIdx]], y_pred[clusters[bestIdx]])\n","        coefs = model.coef_\n","\n","        # # Regular model (LIME)\n","        # model = Ridge()\n","        # model.fit(z_p, z_labs, sample_weight = weights)\n","        # y_pred = model.predict(z_p)\n","        # r2 = model.score(z_p, z_labs, sample_weight = weights)\n","        # mse = metrics.mean_squared_error(z_labs, y_pred, sample_weight=weights)\n","        # coefs = model.coef_\n","        \n","\n","        # print(\"r2:\", r2)\n","        # print()\n","\n","\n","        # This is to store z_p without elipsis\n","        np.set_printoptions(threshold=sys.maxsize)\n","        # Got from: https://stackoverflow.com/questions/25375260/pandas-to-csv-always-substitute-long-numpy-ndarray-with-ellipsis\n","\n","        print(char, abc.index(char), 'type:', type(abc.index(char)))\n","        dict['binMethod'][k].append(BIN_METH.name)\n","        dict['numBins'][k].append(len(binEdges))\n","        dict['binEdges'][k].append(binEdges)\n","        dict['overlapping'][k].append(OVERLAPPING)\n","        dict['sigma'][k].append(sigma)\n","        dict['correct after perturbations %'][k].append(count/charLogits.shape[0])\n","        dict['mse'][k].append(mse)\n","        dict['r2'][k].append(r2)\n","        dict['z_p'][k].append(z_p.tolist())         \n","        dict['z_labs'][k].append(z_labs.tolist()) \n","        dict['weights'][k].append(weights.tolist())   \n","        dict['coefs'][k].append(coefs.tolist())       \n","        dict['origConf'][k].append(z_labs[0])\n","        dict['avgPertConf'][k].append(np.average(z_labs[1:]))\n","        k+=1\n","\n","    # dict['correct perturbations avg'][abc.index(char)] = sum(dict['correct after perturbations %'][abc.index(char)]) / len(dict['correct after perturbations %'][abc.index(char)])\n","    # dict['mse avg'][abc.index(char)] = sum(dict['mse'][abc.index(char)]) / len(dict['mse'][abc.index(char)])\n","    # dict['r2 avg'][abc.index(char)] = sum(dict['r2'][abc.index(char)]) / len(dict['r2'][abc.index(char)])\n","    \n","    #     break\n","    # break\n","\n","for i in range(5): # I think this should be the N = 5 from earlier\n","    dict['mse avg'][i] = sum(dict['mse'][i]) / len(dict['mse'][i])\n","    dict['r2 avg'][i] = sum(dict['r2'][i]) / len(dict['r2'][i])\n","df=pd.DataFrame(dict)\n","# TODO: Change it so you don't have to manually change the name of the file every time\n","# and if you forget to, it doesn't override your last thing of data.\n","df.to_csv('c_2k_TestingGaussian3.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n","                    file_loc   gt transcript  ... alignment_index    st     ed\n","0  cat/9f869f70_nohash_0.wav  cat        cat  ...              33  8160  13279\n","0  cat/f618568f_nohash_0.wav  cat        cat  ...              29  6880  11999\n","0  cat/e9a76b2f_nohash_0.wav  cat        cat  ...              27  6240  11359\n","0  cat/ba676390_nohash_0.wav  cat        cat  ...              33  8160  13279\n","0  cat/db7c95b0_nohash_0.wav  cat        cat  ...              20  4000   9119\n","\n","[5 rows x 7 columns]\n","Normalizing between -20000 and 20000\n","Using 25 evenly spaced bins\n","k is 0\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-438123bb8be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# Forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mbatchLogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;31m# batchLogits = pipeline._model.predict(features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Use softmax on the last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mtrange\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0mOn\u001b[0m \u001b[0mPython3\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \"\"\"\n\u001b[0;32m-> 1526\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"]}]},{"cell_type":"code","metadata":{"id":"lXvWOiG8VglL"},"source":["# print(binEdges)\n","# print(\"correct after perturbations %: \", dict['correct after perturbations %'])\n","# print(\"audio name: \", dict['audio name'])\n","# print(\"normalized: \", dict['normalized'])\n","# print(\"origConf: \", dict['origConf'])\n","# print(\"avgPertConf: \", dict['avgPertConf'])\n","# print(\"binEdges: \", dict['binEdges'])\n","# print(\"mse: \", dict['mse'])\n","# print(\"mse avg: \", dict['mse avg'])\n","# print(\"r2: \", dict['r2'])\n","# print(\"r2 avg: \", dict['r2 avg'])\n","# print(\"coefs: \", dict['coefs'])\n","\n","# dict['binEdges'][0] = list(binEdges)\n","# print(\"binEdges: \", dict['binEdges'])\n","# print(\"binEdges[0]: \", dict['binEdges'][0])\n","\n","\n","\n","# df=pd.DataFrame(dict)\n","# df.to_csv('c_2k_pert0_evenBins.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_hRC6Mg8O6iR"},"source":["print(\"distances:\\n\", d[0:30])\n","print(\"weights:\\n\", weights[0:30])\n","print(\"max distance:\", d[np.argmax(d)])\n","print(\"min distance:\", d[np.argmin(d[1:])])\n","print(\"max weight:\", weights[np.argmax(weights[1:])])\n","print(\"min weight:\", weights[np.argmin(weights)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJLUu4-9XSgC"},"source":["print(\"sqrt of std of distances:\", np.sqrt(np.std(d)))\n","print(\"max distance:\", d[np.argmax(d)])\n","print(\"min weight:\", weights[np.argmin(weights)])\n","print(\"average distance:\", np.average(d))\n","print(\"average weight:\", np.average(weights))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_o_zR6YnP35M"},"source":[""],"execution_count":null,"outputs":[]}]}